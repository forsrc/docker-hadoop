Spark Executor Command: "/tools/jdk1.8.0_192/bin/java" "-cp" "/tools/spark-2.4.0-bin-hadoop2.7/conf/:/tools/spark-2.4.0-bin-hadoop2.7/jars/*:/tools/hadoop-3.1.1/etc/hadoop/:/tools/hadoop-3.1.1/share/hadoop/common/lib/*:/tools/hadoop-3.1.1/share/hadoop/common/*:/tools/hadoop-3.1.1/share/hadoop/hdfs/:/tools/hadoop-3.1.1/share/hadoop/hdfs/lib/*:/tools/hadoop-3.1.1/share/hadoop/hdfs/*:/tools/hadoop-3.1.1/share/hadoop/mapreduce/lib/*:/tools/hadoop-3.1.1/share/hadoop/mapreduce/*:/tools/hadoop-3.1.1/share/hadoop/yarn/:/tools/hadoop-3.1.1/share/hadoop/yarn/lib/*:/tools/hadoop-3.1.1/share/hadoop/yarn/*:/tools/jdk1.8.0_192/lib/tools.jar" "-Xmx1024M" "-Dspark.driver.port=55974" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@thinkpad.localdomain:55974" "--executor-id" "0" "--hostname" "172.25.0.11" "--cores" "1" "--app-id" "app-20181109154013-0001" "--worker-url" "spark://Worker@172.25.0.11:37061"
========================================

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/tools/spark-2.4.0-bin-hadoop2.7/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/tools/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
18/11/09 15:40:19 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 617@hadoop-slave1
18/11/09 15:40:19 INFO SignalUtils: Registered signal handler for TERM
18/11/09 15:40:19 INFO SignalUtils: Registered signal handler for HUP
18/11/09 15:40:19 INFO SignalUtils: Registered signal handler for INT
18/11/09 15:40:20 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
18/11/09 15:40:20 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
18/11/09 15:40:20 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
18/11/09 15:40:20 DEBUG MetricsSystemImpl: UgiMetrics, User and group related metrics
18/11/09 15:40:21 DEBUG Shell: setsid exited with exit code 0
18/11/09 15:40:21 DEBUG KerberosName: Kerberos krb5 configuration not found, setting default realm to empty
18/11/09 15:40:21 DEBUG Groups:  Creating new Groups object
18/11/09 15:40:21 DEBUG NativeCodeLoader: Trying to load the custom-built native-hadoop library...
18/11/09 15:40:21 DEBUG NativeCodeLoader: Loaded the native-hadoop library
18/11/09 15:40:21 DEBUG JniBasedUnixGroupsMapping: Using JniBasedUnixGroupsMapping for Group resolution
18/11/09 15:40:21 DEBUG JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
18/11/09 15:40:21 DEBUG Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
18/11/09 15:40:21 DEBUG SparkHadoopUtil: creating UGI for user: litianzhi
18/11/09 15:40:21 DEBUG UserGroupInformation: hadoop login
18/11/09 15:40:21 DEBUG UserGroupInformation: hadoop login commit
18/11/09 15:40:21 DEBUG UserGroupInformation: using local user:UnixPrincipal: root
18/11/09 15:40:21 DEBUG UserGroupInformation: Using user: "UnixPrincipal: root" with name root
18/11/09 15:40:21 DEBUG UserGroupInformation: User entry: "root"
18/11/09 15:40:21 DEBUG UserGroupInformation: UGI loginUser:root (auth:SIMPLE)
18/11/09 15:40:21 DEBUG UserGroupInformation: PrivilegedAction as:litianzhi (auth:SIMPLE) from:org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:64)
18/11/09 15:40:21 INFO SecurityManager: Changing view acls to: root,litianzhi
18/11/09 15:40:21 INFO SecurityManager: Changing modify acls to: root,litianzhi
18/11/09 15:40:21 INFO SecurityManager: Changing view acls groups to: 
18/11/09 15:40:21 INFO SecurityManager: Changing modify acls groups to: 
18/11/09 15:40:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, litianzhi); groups with view permissions: Set(); users  with modify permissions: Set(root, litianzhi); groups with modify permissions: Set()
18/11/09 15:40:22 DEBUG InternalLoggerFactory: Using SLF4J as the default logging framework
18/11/09 15:40:22 DEBUG InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
18/11/09 15:40:22 DEBUG InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
18/11/09 15:40:22 DEBUG MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 12
18/11/09 15:40:22 DEBUG PlatformDependent0: -Dio.netty.noUnsafe: false
18/11/09 15:40:22 DEBUG PlatformDependent0: Java version: 8
18/11/09 15:40:22 DEBUG PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
18/11/09 15:40:22 DEBUG PlatformDependent0: sun.misc.Unsafe.copyMemory: available
18/11/09 15:40:22 DEBUG PlatformDependent0: java.nio.Buffer.address: available
18/11/09 15:40:22 DEBUG PlatformDependent0: direct buffer constructor: available
18/11/09 15:40:22 DEBUG PlatformDependent0: java.nio.Bits.unaligned: available, true
18/11/09 15:40:22 DEBUG PlatformDependent0: jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
18/11/09 15:40:22 DEBUG PlatformDependent0: java.nio.DirectByteBuffer.<init>(long, int): available
18/11/09 15:40:22 DEBUG PlatformDependent: sun.misc.Unsafe: available
18/11/09 15:40:22 DEBUG PlatformDependent: -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
18/11/09 15:40:22 DEBUG PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
18/11/09 15:40:22 DEBUG PlatformDependent: -Dio.netty.noPreferDirect: false
18/11/09 15:40:22 DEBUG PlatformDependent: -Dio.netty.maxDirectMemory: 954728448 bytes
18/11/09 15:40:22 DEBUG PlatformDependent: -Dio.netty.uninitializedArrayAllocationThreshold: -1
18/11/09 15:40:22 DEBUG CleanerJava6: java.nio.ByteBuffer.cleaner(): available
18/11/09 15:40:22 DEBUG NioEventLoop: -Dio.netty.noKeySetOptimization: false
18/11/09 15:40:22 DEBUG NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
18/11/09 15:40:22 DEBUG PlatformDependent: org.jctools-core.MpscChunkedArrayQueue: available
18/11/09 15:40:22 DEBUG ResourceLeakDetector: -Dio.netty.leakDetection.level: simple
18/11/09 15:40:22 DEBUG ResourceLeakDetector: -Dio.netty.leakDetection.targetRecords: 4
18/11/09 15:40:22 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 9
18/11/09 15:40:22 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 9
18/11/09 15:40:22 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
18/11/09 15:40:22 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
18/11/09 15:40:22 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
18/11/09 15:40:22 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.tinyCacheSize: 512
18/11/09 15:40:22 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
18/11/09 15:40:22 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
18/11/09 15:40:22 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
18/11/09 15:40:22 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
18/11/09 15:40:22 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.useCacheForAllThreads: true
18/11/09 15:40:22 DEBUG TransportClientFactory: Creating new connection to thinkpad.localdomain/10.0.75.1:55974
18/11/09 15:40:22 DEBUG DefaultChannelId: -Dio.netty.processId: 617 (auto-detected)
18/11/09 15:40:22 DEBUG NetUtil: -Djava.net.preferIPv4Stack: false
18/11/09 15:40:22 DEBUG NetUtil: -Djava.net.preferIPv6Addresses: false
18/11/09 15:40:22 DEBUG NetUtil: Loopback interface: lo (lo, 127.0.0.1)
18/11/09 15:40:22 DEBUG NetUtil: /proc/sys/net/core/somaxconn: 128
18/11/09 15:40:22 DEBUG DefaultChannelId: -Dio.netty.machineId: 02:42:ac:ff:fe:19:00:0b (auto-detected)
18/11/09 15:40:22 DEBUG ByteBufUtil: -Dio.netty.allocator.type: pooled
18/11/09 15:40:22 DEBUG ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 65536
18/11/09 15:40:22 DEBUG ByteBufUtil: -Dio.netty.maxThreadLocalCharBufferSize: 16384
18/11/09 15:40:22 DEBUG AbstractByteBuf: -Dio.netty.buffer.bytebuf.checkAccessible: true
18/11/09 15:40:22 DEBUG ResourceLeakDetectorFactory: Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@12f6df9e
18/11/09 15:40:22 DEBUG TransportClientFactory: Connection to thinkpad.localdomain/10.0.75.1:55974 successful, running bootstraps...
18/11/09 15:40:22 INFO TransportClientFactory: Successfully created connection to thinkpad.localdomain/10.0.75.1:55974 after 237 ms (0 ms spent in bootstraps)
18/11/09 15:40:22 DEBUG Recycler: -Dio.netty.recycler.maxCapacityPerThread: 32768
18/11/09 15:40:22 DEBUG Recycler: -Dio.netty.recycler.maxSharedCapacityFactor: 2
18/11/09 15:40:22 DEBUG Recycler: -Dio.netty.recycler.linkCapacity: 16
18/11/09 15:40:22 DEBUG Recycler: -Dio.netty.recycler.ratio: 8
18/11/09 15:40:23 INFO SecurityManager: Changing view acls to: root,litianzhi
18/11/09 15:40:23 INFO SecurityManager: Changing modify acls to: root,litianzhi
18/11/09 15:40:23 INFO SecurityManager: Changing view acls groups to: 
18/11/09 15:40:23 INFO SecurityManager: Changing modify acls groups to: 
18/11/09 15:40:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, litianzhi); groups with view permissions: Set(); users  with modify permissions: Set(root, litianzhi); groups with modify permissions: Set()
18/11/09 15:40:23 DEBUG SparkEnv: Using serializer: class org.apache.spark.serializer.JavaSerializer
18/11/09 15:40:23 DEBUG TransportClientFactory: Creating new connection to thinkpad.localdomain/10.0.75.1:55974
18/11/09 15:40:23 DEBUG TransportClientFactory: Connection to thinkpad.localdomain/10.0.75.1:55974 successful, running bootstraps...
18/11/09 15:40:23 INFO TransportClientFactory: Successfully created connection to thinkpad.localdomain/10.0.75.1:55974 after 9 ms (0 ms spent in bootstraps)
18/11/09 15:40:23 INFO DiskBlockManager: Created local directory at /works/spark/spark-80b5f426-f59f-478b-bb65-3dbda5e8c6dd/executor-3f814e39-7168-4ee6-8426-5352d5a054bc/blockmgr-26658e25-f953-4ec0-b72b-2c3f1b7f6741
18/11/09 15:40:23 DEBUG DiskBlockManager: Adding shutdown hook
18/11/09 15:40:23 DEBUG ShutdownHookManager: Adding shutdown hook
18/11/09 15:40:23 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/11/09 15:40:24 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@thinkpad.localdomain:55974
18/11/09 15:40:24 INFO WorkerWatcher: Connecting to worker spark://Worker@172.25.0.11:37061
18/11/09 15:40:24 DEBUG TransportClientFactory: Creating new connection to /172.25.0.11:37061
18/11/09 15:40:24 DEBUG TransportClientFactory: Connection to /172.25.0.11:37061 successful, running bootstraps...
18/11/09 15:40:24 INFO TransportClientFactory: Successfully created connection to /172.25.0.11:37061 after 26 ms (0 ms spent in bootstraps)
18/11/09 15:40:24 INFO WorkerWatcher: Successfully connected to spark://Worker@172.25.0.11:37061
18/11/09 15:40:24 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
18/11/09 15:40:24 INFO Executor: Starting executor ID 0 on host 172.25.0.11
18/11/09 15:40:25 DEBUG TransportServer: Shuffle server started on port: 42143
18/11/09 15:40:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42143.
18/11/09 15:40:25 INFO NettyBlockTransferService: Server created on 172.25.0.11:42143
18/11/09 15:40:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/11/09 15:40:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.25.0.11, 42143, None)
18/11/09 15:40:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.25.0.11, 42143, None)
18/11/09 15:40:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.25.0.11, 42143, None)
18/11/09 15:40:26 ERROR Inbox: Ignoring error
java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at java.io.DataInputStream.readUTF(DataInputStream.java:609)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.spark.scheduler.TaskDescription$$anonfun$decode$1.apply(TaskDescription.scala:134)
	at org.apache.spark.scheduler.TaskDescription$$anonfun$decode$1.apply(TaskDescription.scala:133)
	at scala.collection.immutable.Range.foreach(Range.scala:160)
	at org.apache.spark.scheduler.TaskDescription$.decode(TaskDescription.scala:133)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:96)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/11/09 15:51:21 WARN TransportChannelHandler: Exception in connection from thinkpad.localdomain/10.0.75.1:55974
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
18/11/09 15:51:21 ERROR CoarseGrainedExecutorBackend: Executor self-exiting due to : Driver thinkpad.localdomain:55974 disassociated! Shutting down.
18/11/09 15:51:21 INFO DiskBlockManager: Shutdown hook called
18/11/09 15:51:21 ERROR CoarseGrainedExecutorBackend: RECEIVED